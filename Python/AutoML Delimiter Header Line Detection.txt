AutoML Delimiter detection

    If the dataset is of type
        1) Market Basket list
    then the delimiter won't occur the same number of times on each row. In that case the delimiter 
    is the most frequent char in the sample (first 100 lines) between |¦,; and [tab]
    Moreover, If the dataset is 1) Market Basket list, then it has no header line.

    On the contrary, the delimiter /should/ occur the same number of times on
    each row if the dataset is of the type: 
        2) Order/Invoice detail
        3) Sparse item Dataset
        4) Columns with multiple categorized values
    However, due to malformed data, it may not. We don't want
    an all or nothing approach, so we allow for small variations in this
    number.
    The steps in order to detect delimiter are:
      1) build a table of the frequency of each character on every line.
      2) build a table of frequencies of this frequency (meta-frequency?),
         e.g.  'x occurred 5 times in 10 rows, 6 times in 1000 rows,
         7 times in 2 rows'
      3) use the mode of the meta-frequency to determine the /expected/
         frequency for that character
      4) find out how often the character actually meets that goal
      5) the character that best meets its goal is the delimiter
      6) Malliaridis 20231209 If more than one delimiters found as candidates then the 'Winner' is
         the delimiter thaw has the highest frequency and is one of the 'preferred' 
         in that order [';', ',', '\t', ' ', ':']
    For performance reasons, the data is evaluated in chunks, so it can
    try and evaluate the smallest portion of the data possible, evaluating
    additional chunks as necessary.

    The library used to achieve delimiter detection is the csv.py. Its source code can be found in
    https://github.com/python/cpython/blob/3.12/Lib/csv.py
    The above library has been modified by us in order to extend delimiter detection capability for the 
        1) Market Basket list datasets
    which was not included in the original library.
    The modified subroutine is:
        _guess_delimiter 

----------------------------
AutoML Header line detection

    The header line detection procedure according to csv.py python library occurs as follows:
        1. A dictionary of types of data in each column is created at first. 
        2. If any column is of a single type (say, integers), *except* for the first row, 
           then the first row is presumed to be labels. 
        3. If the dataset is 1) Market Basket list, then there is no header line 
        4. If the type can't be determined, it is assumed to be a string in which case
           the length of the string is the determining factor: 
           4.1. If all of the rows except for the first are the same length, it's a header.
           4.2. Finally, a 'vote' is taken at the end for each column, adding or
                subtracting from the likelihood of the first row being a header.
    
    From the above rules, the 3rd one added by us to improve header line detection for
            1) Market Basket list datasets



Dataset classification
Dataset Categories:
1) Market Basket list: Easy to be identified with almost 100% accuracy without AutoML
   The main characteristic is that it has its delimiter ΝΟΤ occur the same number of times on each row.
2) Order/Invoice detail: Its main characteristic is to identify the column that plays the role of the order id 
                         and to identify the column that plays the role of product.
3) Sparse item Dataset: Its main characteristic is to find the value that describes the absence of column
4) Columns with multiple categorized values: The only category after 1) Market Basket list that cna have no header line
0) Dataset that are of no interest for association rules mining. Usually has numerical data in high range

2,3,4,0 type of datasets are candidates for ML techniques

Features candidates
1) V Avg of different values per column          Range [0...1]  --> It is the number of unique values per column divided by the number of rows For every column and compute the average over all columns 
2) V Avg of different values over all Columns    Range [0...1]  --> It is the number of unique values divided by the items of the sample dataset
3) V Avg of different values per row             Range [0...1]  --> It is the number of unique values per row divided by the number of columns For every row and compute the average over all rows 
4) V frequency of the most frequent value        Range [0...1]  --> It is the number of the most frequent value divided by by the items of the sample dataset
5) V frequency of the second most frequent value Range [0...1]  --> It is the number of the second most frequent value divided by by the items of the sample dataset
6) V frequency of the third most frequent value  Range [0...1]  --> It is the number of the third most frequent value divided by by the items of the sample dataset
7) V Number of Columns                           Range [1.Inf]  --> It is the number of columns of the sample dataset
                                8+9+10+11+12=1
08) V Freq Number of Integer Columns             Range [0...1]  --> It is the number of columns with integer items divided by the number of all columns
09) V Freq Number of Decimal/float Columns       Range [0...1]  --> It is the number of columns with decimal items divided by the number of all columns
10) V Freq Number of Date Columns                Range [0...1]  --> It is the number of columns with date items divided by the number of all columns
11)V Freq Number of string Columns               Range [0...1]  --> It is the number of columns with string or other items divided by the number of all columns
12)V Freq Number of boolean columns              Range [0...1]  --> It is the number of columns with boolean items divided by the number of all columns
13)V Min item length                             Range [1.Inf]  --> It is the minimum length of items in the sample dataset
14)V Max item length                             Range [1.Inf]  --> It is the maximum length of items in the sample dataset
15)V Avg item length                             Range [1.Inf]  --> It is the average length of items in the sample dataset
16)V Freq of 1 character columns                 Range [0...1]  --> It is the number of columns with only one character length items divided by the number of all columns
17)V Freq of Columns that have items with only 2 values Range [0...1]  --> It is the number of columns with only 2 different values divided by the number of all columns
18)V Has header                                  Range [0,1]    --> 0 If dataset has no header, 1 if it has
19)V datasetType                                 Range [0,2,3,4]--> It is the type of the dataset and it is the class Y
20)V delimiter                                                      It is the delimiter of the dataset               


Installation of MySQL Connector is needed in order to link Python with mySQL database 
Run the command below in cmd
pip install mysql-connector-python


keel dataset 
uci repo


Decition Tree
Random Forest
SVM
Knn (IbK)


ΕΛΙΔΕΚ
stoug@ihu.gr
Mpalalaika$1